		 GNB
--------------------------------------------------
		 Best parameters:
  - var_smoothing=0.000797
--------------------------------------------------

The accuracy score that we get is:  0.8641304347826086

 Confusion Matrix:  [[144   7]
 [ 18  15]]
              precision    recall  f1-score   support

           0       0.89      0.95      0.92       151
           1       0.68      0.45      0.55        33

   micro avg       0.86      0.86      0.86       184
   macro avg       0.79      0.70      0.73       184
weighted avg       0.85      0.86      0.85       184

--------------------------------------------------
		 LDA
--------------------------------------------------
		 Best parameters:
  - n_components=8
  - tol=0.058093
--------------------------------------------------

The accuracy score that we get is:  0.8695652173913043

 Confusion Matrix:  [[144   7]
 [ 17  16]]
              precision    recall  f1-score   support

           0       0.89      0.95      0.92       151
           1       0.70      0.48      0.57        33

   micro avg       0.87      0.87      0.87       184
   macro avg       0.80      0.72      0.75       184
weighted avg       0.86      0.87      0.86       184

--------------------------------------------------
		 Gaussian Process Classifier
--------------------------------------------------
		 Best parameters:
  - n_restarts_optimizer=0
  - max_iter_predict=39
  - n_jobs=3
--------------------------------------------------

The accuracy score that we get is:  0.7989130434782609

 Confusion Matrix:  [[140  11]
 [ 26   7]]
              precision    recall  f1-score   support

           0       0.84      0.93      0.88       151
           1       0.39      0.21      0.27        33

   micro avg       0.80      0.80      0.80       184
   macro avg       0.62      0.57      0.58       184
weighted avg       0.76      0.80      0.77       184

--------------------------------------------------
Best parameters MLP Hyper-parameters:
    - alpha=0
    - tol =0.031294
    - batch_size=46
    - momentum=0.450621
    - learning_rate_init=0.145296
    - max_iterations=13
    - hidden layers sizes=86
--------------------------------------------------

The accuracy score that we get is:  0.8315217391304348

 Confusion Matrix:  [[142   9]
 [ 22  11]]
              precision    recall  f1-score   support

           0       0.87      0.94      0.90       151
           1       0.55      0.33      0.42        33

   micro avg       0.83      0.83      0.83       184
   macro avg       0.71      0.64      0.66       184
weighted avg       0.81      0.83      0.81       184

--------------------------------------------------
		 Best parameters Logistic Regression:
    - C=1
    - max_iter=77.000000
    - n_jobs=5
    - intercept_scaling=3
    - tol=0
    - verbose=9
--------------------------------------------------

The accuracy score that we get is:  0.875

 Confusion Matrix:  [[148   3]
 [ 20  13]]
              precision    recall  f1-score   support

           0       0.88      0.98      0.93       151
           1       0.81      0.39      0.53        33

   micro avg       0.88      0.88      0.88       184
   macro avg       0.85      0.69      0.73       184
weighted avg       0.87      0.88      0.86       184

--------------------------------------------------
Hard Voting Classifier
--------------------------------------------------
0.8586956521739131
              precision    recall  f1-score   support

           0       0.89      0.95      0.92       151
           1       0.65      0.45      0.54        33

   micro avg       0.86      0.86      0.86       184
   macro avg       0.77      0.70      0.73       184
weighted avg       0.85      0.86      0.85       184

--------------------------------------------------
