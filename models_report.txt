Best parameters MLP Hyper-parameters:
    - alpha=0
    - tol =0.031294
    - batch_size=46
    - momentum=0.450621
    - learning_rate_init=0.145296
    - max_iterations=13
    - hidden layers sizes=86
--------------------------------------------------

The accuracy score that we get is:  0.8315217391304348

 Confusion Matrix:  [[142   9]
 [ 22  11]]
              precision    recall  f1-score   support

           0       0.87      0.94      0.90       151
           1       0.55      0.33      0.42        33

   micro avg       0.83      0.83      0.83       184
   macro avg       0.71      0.64      0.66       184
weighted avg       0.81      0.83      0.81       184

--------------------------------------------------
		 Best parameters Logistic Regression:
    - C=1
    - max_iter=77.000000
    - n_jobs=5
    - intercept_scaling=3
    - tol=0
    - verbose=9
--------------------------------------------------

The accuracy score that we get is:  0.875

 Confusion Matrix:  [[148   3]
 [ 20  13]]
              precision    recall  f1-score   support

           0       0.88      0.98      0.93       151
           1       0.81      0.39      0.53        33

   micro avg       0.88      0.88      0.88       184
   macro avg       0.85      0.69      0.73       184
weighted avg       0.87      0.88      0.86       184

--------------------------------------------------
